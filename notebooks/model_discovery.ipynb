{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rudy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import pandas\n",
    "import math\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device('cpu')\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
    "from huggingface_hub import hf_hub_download\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizer = pipeline(\"summarization\", model=\"sambydlo/scientific_abstract_simplification-tomasg25/scientific_lay_summarisation\")\n",
    "model_name = [\n",
    "                \"sambydlo/bart-large-scientific-lay-summarisation\",\n",
    "                \"haining/scientific_abstract_simplification\",\n",
    "                \"philschmid/bart-large-cnn-samsum\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(model_name[0])\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"\"\"We present numerical spectral and vertical structure calculations appropriate for \n",
    "            near-Eddington luminosity, radiation pressure dominated accretion disks\n",
    "            around stellar mass black holes. We cover a wide range of black hole spins, and\n",
    "            incorporate dissipation profiles based on first-principles three-dimensional MHD\n",
    "            disk interior simulations. We also include non-zero stresses at the ISCO, which\n",
    "            results in the disk effective temperature to increase rapidly towards the black\n",
    "            hole, and give rise to rather extreme conditions with high temperatures and low\n",
    "            surface densities. We found that local annuli spectra become increasingly characteristic \n",
    "            of saturated Comptonisation with decreasing distance to the black hole.\n",
    "            While the spectra becomes harder with increasing black hole spin, they do not\n",
    "            give rise to a broad power law tail even at maximum spin. We discuss the implications \n",
    "            of our results in the context of the steep power law (SPL) state and the\n",
    "            associated high-frequency quasi-periodic oscillations (HFQPO) observed in some\n",
    "            X-ray binary systems\"\"\"\n",
    "introduction = \"\"\"Galactic black hole X-ray binaries (BHB) show several states of outburst distinguished\n",
    "by luminosity, spectral shape and variability (see for example, McClintock & Remillard\n",
    "(2006) and Done, Gierlinski, & Kubota (2007)). In particular, at their highest luminosities\n",
    "the spectra contains a steep power law component with photon index Γ > 2.4 (McClintock & Remillard\n",
    "2006). These energetically significant power law tails begin at the spectral peak (≈ 10 keV)\n",
    "and could extend into the MeV regime (Ling & Wheaton 2005; Grove et al. 1998). Moreover, this steep power \n",
    "law (SPL) spectral state is accompanied by high-frequency (ν > 50 Hz)\n",
    "quasi-periodic oscillations (HFQPO) in the light curves when integrated over approximately\n",
    "10 to 30 keV in photon energies.\n",
    "Understanding the first-principles physics of radiating accretion flows that presumably\n",
    "underly these observational properties remain an important outstanding problem in astrophysics. The standard thin accretion disk model (Shakura & Sunyaev 1973; Novikov & Thorne\n",
    "1973; Riffert & Herold 1995) assumed that the stress and luminosity at the innermost stable\n",
    "circular orbit (ISCO) drops to zero, and that at this point the material essentially simply disappears into the black hole. This assumption received significant recent theoretical scrutiny\n",
    "upon the realization that magnetohydrodynamic turbulence (Balbus and Hawley 1991, 1998)\n",
    "is probably the source of stress that drives accretion. In particular, Agol and Krolik (2000)\n",
    "demonstrated that having non-zero magnetic stresses at the ISCO can cause the effective\n",
    "temperature to rise sharply towards the black hole instead of fall to zero as predicted by\n",
    "the standard model. Among the potentially observable consequences postulated by these\n",
    "authors, the inner disk consequently becomes effectively thin, and extends the spectrum to\n",
    "higher frequencies.\n",
    "More recently, Dexter & Blaes (2014) (from here on referred to as DB14) proposed that\n",
    "the Agol and Krolik (2000) model provides feasible mechanism for explaining both the steep\n",
    "power law (SPL) state seen at near Eddington luminosities and the associated high frequency\n",
    "quasi-periodic oscillations (HFQPO). These authors argued that the rapidly rising effective\n",
    "temperature with decreasing distance to the black hole would give rise to the SPL spectra,\n",
    "while also providing a natural filter for the HFQPOs that do not require the entire disk to\n",
    "oscillate coherently.\n",
    "In this work, we undertake a detailed numerical study of the structure and spectra of\n",
    "near-Eddington accretion disks with non-zero magnetic stresses the ISCO, and particularly\n",
    "focus on the effects of black hole spin. Unlike previous efforts that relied on one-zone models,\n",
    "we self-consistently couple vertical structure to radiative transfer at each disk annuli, and\n",
    "generate spectra that fully incorporates effects Comptonisation and metal opacities. Our\n",
    "inputs are time and horizontally averaged vertical dissipation profiles from first-principles\n",
    "stratified shearing-box simulations of accretion flows (Hirose, Krolik & Blaes 2009). These\n",
    "calculations evolve the time-dependent three-dimensional radiation magneto-hydrodynamic\n",
    "equations and accounts for the tidal vertical gravity from the black hole. In simulations over\n",
    "a wide range of box-integrated radiation to gas pressure ratios, the resulting vertical spatial\n",
    "dissipation profiles generally peak at around a pressure scale-height away from the disk\n",
    "mid-plane, and should capture the effects of MRI turbulence. Moreover, these simulations\n",
    "collectively indicate that the α-prescription (Shakura & Sunyaev 1973) relationship between\n",
    "pressure and stress approximately hold (Hirose, Blaes & Krolik 2009). This means we are \n",
    "justified, at least in light of recent simulations, to use the α-model with modifications to\n",
    "account for non-zero inner torque to generate radial profiles of total surface density Σ0 and\n",
    "effective temperature Teff that are also necessary for our vertical structure and radiative\n",
    "transfer computations.\n",
    "This paper is organized as follows. In section 2 we outline our numerical methods, paying\n",
    "particular attention to how we incorporated non-zero inner torque. Section 3 showcases our\n",
    "numerical results, including full-disk spectra for all black hole spin values we covered. We\n",
    "turn to the possibility of HFQPOs in section 4, and conclude in section 5 with a discussion\n",
    "of on-going and future work.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.word_tokenize(introduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_input_text(input_text: str, batch_size: int=819) -> list:\n",
    "    \"\"\"\n",
    "    :param input_text: str, research paper in full\n",
    "    :param batch_size: int, 80% of max input tokens \n",
    "    :return: list, batched input text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokens = nltk.word_tokenize(input_text)\n",
    "        n_batches = math.ceil(len(tokens) / batch_size)\n",
    "\n",
    "        if len(tokens) > batch_size:\n",
    "            batches = [\" \".join(tokens[(i * batch_size):((i + 1) * batch_size)]) \n",
    "                    for i in range(n_batches)]\n",
    "        else:\n",
    "            batches = [\" \".join(tokens)]\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate summary from Arxiv research article.\n",
    "\n",
    "    \"\"\"\n",
    "    # Start clock\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Check length of article and batch if necessary\n",
    "        batches = batch_input_text(input_text)\n",
    "        # Summarize batches\n",
    "        sub_summaries = []\n",
    "        for i in range(len(batches)):\n",
    "            output = model.generate(input_ids=tokenizer.encode(batches[i], return_tensors=\"pt\").to(device),\n",
    "                                    max_length=350)\n",
    "            summary = tokenizer.decode(output[0])\n",
    "            sub_summaries.append(summary)\n",
    "        print(sub_summaries)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(input_text: str, device: str='cpu') -> str:\n",
    "    \"\"\"\n",
    "    Generate summary from Arxiv research article.\n",
    "\n",
    "    \"\"\"\n",
    "    # Start clock\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Set model and torch method\n",
    "    model_name = [\n",
    "                \"sambydlo/bart-large-scientific-lay-summarisation\",\n",
    "                # \"haining/scientific_abstract_simplification\",\n",
    "                \"philschmid/bart-large-cnn-samsum\"\n",
    "            ]\n",
    "    device = torch.device(device)\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name[1])\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name[1]).to(device)\n",
    "\n",
    "    try:\n",
    "        # Check length of article and batch if necessary\n",
    "        batches = batch_input_text(input_text)\n",
    "        # Summarize batches\n",
    "        sub_summaries = []\n",
    "        for i in range(len(batches)):\n",
    "            output = model.generate(input_ids=tokenizer.encode(batches[i], return_tensors=\"pt\").to(device),\n",
    "                                    max_length=500)\n",
    "            summary = tokenizer.decode(output[0])\n",
    "            sub_summaries.append(summary)\n",
    "        \n",
    "        # Combine child summaries & remove specified separators\n",
    "        joined_summaries = \" \".join(sub_summaries)\n",
    "        parent_input = joined_summaries.replace(\"</s><s><s><s>\", \"\").replace(\"</s>\", \"\")\n",
    "\n",
    "        # Obtain final summary\n",
    "        output = model.generate(input_ids=tokenizer.encode(parent_input, return_tensors=\"pt\").to(device),\n",
    "                                max_length=500)\n",
    "        summary = tokenizer.decode(output[0])\n",
    "        summary = summary.replace(\"</s><s><s><s>\", \"\").replace(\"</s>\", \"\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "def batch_input_text(input_text: str, batch_size: int=819) -> list:\n",
    "    \"\"\"\n",
    "    :param input_text: str, research paper in full\n",
    "    :param batch_size: int, 80% of max input tokens \n",
    "    :return: list, batched input text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokens = nltk.word_tokenize(input_text)\n",
    "        n_batches = math.ceil(len(tokens) / batch_size)\n",
    "\n",
    "        if len(tokens) > batch_size:\n",
    "            batches = [\" \".join(tokens[(i * batch_size):((i + 1) * batch_size)]) \n",
    "                    for i in range(n_batches)]\n",
    "        else:\n",
    "            batches = [\" \".join(tokens)]\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_summary(introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.99 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4407"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "batches = batch_input_text(introduction, batch_size=200)\n",
    "len(introduction)\n",
    "# s = 0\n",
    "# for i in batches:\n",
    "#     s += 1\n",
    "#     print(f\"Batch {s} token count: {len(i)}\")\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s><s>Galactic black hole X-ray binaries (BHBs ) show several states of outburst distinguished by luminosity, spectral shape and variability (see for example, McClintock & Remillard (2006) and Done, Gierlinski, & Kubota (2007)). In particular, at their highest luminosities the spectra contains a steep power law component with photon index Γ > 2.4 (McClintock and Remillard2006). These energetically significant power law tails begin at the spectral peak (≈ 10 keV) and could extend into the MeV regime (Ling & Wheaton 2005; Grove et al. 1998). Moreover, this steep power</s>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(input_ids=tokenizer.encode(introduction, return_tensors='pt').to(device), max_length=350)\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
